{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4c47f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#函数库\n",
    "import time\n",
    "import gc\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c683c690",
   "metadata": {},
   "outputs": [],
   "source": [
    "byte=np.array([\n",
    "0x63, 0x7c, 0x77, 0x7b, 0xf2, 0x6b, 0x6f, 0xc5, 0x30, 0x01, 0x67, 0x2b, 0xfe, 0xd7, 0xab, 0x76,\n",
    "0xca, 0x82, 0xc9, 0x7d, 0xfa, 0x59, 0x47, 0xf0, 0xad, 0xd4, 0xa2, 0xaf, 0x9c, 0xa4, 0x72, 0xc0,\n",
    "0xb7, 0xfd, 0x93, 0x26, 0x36, 0x3f, 0xf7, 0xcc, 0x34, 0xa5, 0xe5, 0xf1, 0x71, 0xd8, 0x31, 0x15,\n",
    "0x04, 0xc7, 0x23, 0xc3, 0x18, 0x96, 0x05, 0x9a, 0x07, 0x12, 0x80, 0xe2, 0xeb, 0x27, 0xb2, 0x75,\n",
    "0x09, 0x83, 0x2c, 0x1a, 0x1b, 0x6e, 0x5a, 0xa0, 0x52, 0x3b, 0xd6, 0xb3, 0x29, 0xe3, 0x2f, 0x84,\n",
    "0x53, 0xd1, 0x00, 0xed, 0x20, 0xfc, 0xb1, 0x5b, 0x6a, 0xcb, 0xbe, 0x39, 0x4a, 0x4c, 0x58, 0xcf,\n",
    "0xd0, 0xef, 0xaa, 0xfb, 0x43, 0x4d, 0x33, 0x85, 0x45, 0xf9, 0x02, 0x7f, 0x50, 0x3c, 0x9f, 0xa8,\n",
    "0x51, 0xa3, 0x40, 0x8f, 0x92, 0x9d, 0x38, 0xf5, 0xbc, 0xb6, 0xda, 0x21, 0x10, 0xff, 0xf3, 0xd2,\n",
    "0xcd, 0x0c, 0x13, 0xec, 0x5f, 0x97, 0x44, 0x17, 0xc4, 0xa7, 0x7e, 0x3d, 0x64, 0x5d, 0x19, 0x73,\n",
    "0x60, 0x81, 0x4f, 0xdc, 0x22, 0x2a, 0x90, 0x88, 0x46, 0xee, 0xb8, 0x14, 0xde, 0x5e, 0x0b, 0xdb,\n",
    "0xe0, 0x32, 0x3a, 0x0a, 0x49, 0x06, 0x24, 0x5c, 0xc2, 0xd3, 0xac, 0x62, 0x91, 0x95, 0xe4, 0x79,\n",
    "0xe7, 0xc8, 0x37, 0x6d, 0x8d, 0xd5, 0x4e, 0xa9, 0x6c, 0x56, 0xf4, 0xea, 0x65, 0x7a, 0xae, 0x08,\n",
    "0xba, 0x78, 0x25, 0x2e, 0x1c, 0xa6, 0xb4, 0xc6, 0xe8, 0xdd, 0x74, 0x1f, 0x4b, 0xbd, 0x8b, 0x8a,\n",
    "0x70, 0x3e, 0xb5, 0x66, 0x48, 0x03, 0xf6, 0x0e, 0x61, 0x35, 0x57, 0xb9, 0x86, 0xc1, 0x1d, 0x9e,\n",
    "0xe1, 0xf8, 0x98, 0x11, 0x69, 0xd9, 0x8e, 0x94, 0x9b, 0x1e, 0x87, 0xe9, 0xce, 0x55, 0x28, 0xdf,\n",
    "0x8c, 0xa1, 0x89, 0x0d, 0xbf, 0xe6, 0x42, 0x68, 0x41, 0x99, 0x2d, 0x0f, 0xb0, 0x54, 0xbb, 0x16\n",
    "])\n",
    "key1=np.array([\n",
    "0x0f ,0x15 ,0x71 ,0xc9 ,0x47 ,0xd9 ,0xe8 ,0x59 ,0x0c ,0xb7 ,0xad ,0xd6 ,0xaf ,0x7f ,0x67 ,0x98,\n",
    "0xdc ,0x90 ,0x37 ,0xb0 ,0x9b ,0x49 ,0xdf ,0xe9 ,0x97 ,0xfe ,0x72 ,0x3f ,0x38 ,0x81 ,0x15 ,0xa7,\n",
    "0xd2 ,0xc9 ,0x6b ,0xb7 ,0x49 ,0x80 ,0xb4 ,0x5e ,0xde ,0x7e ,0xc6 ,0x61 ,0xe6 ,0xff ,0xd3 ,0xc6,\n",
    "0xc0 ,0xaf ,0xdf ,0x39 ,0x89 ,0x2f ,0x6b ,0x67 ,0x57 ,0x51 ,0xad ,0x06 ,0xb1 ,0xae ,0x7e ,0xc0,\n",
    "0x2c ,0x5c ,0x65 ,0xf1 ,0xa5 ,0x73 ,0x0e ,0x96 ,0xf2 ,0x22 ,0xa3 ,0x90 ,0x43 ,0x8c ,0xdd ,0x50,\n",
    "0x58 ,0x9d ,0x36 ,0xeb ,0xfd ,0xee ,0x38 ,0x7d ,0x0f ,0xcc ,0x9b ,0xed ,0x4c ,0x40 ,0x46 ,0xbd,\n",
    "0x71 ,0xc7 ,0x4c ,0xc2 ,0x8c ,0x29 ,0x74 ,0xbf ,0x83 ,0xe5 ,0xef ,0x52 ,0xcf ,0xa5 ,0xa9 ,0xef,\n",
    "0x37 ,0x14 ,0x93 ,0x48 ,0xbb ,0x3d ,0xe7 ,0xf7 ,0x38 ,0xd8 ,0x08 ,0xa5 ,0xf7 ,0x7d ,0xa1 ,0x4a,\n",
    "0x48 ,0x26 ,0x45 ,0x20 ,0xf3 ,0x1b ,0xa2 ,0xd7 ,0xcb ,0xc3 ,0xaa ,0x72 ,0x3c ,0xbe ,0x0b ,0x38,\n",
    "0xfd ,0x0d ,0x42 ,0xcb ,0x0e ,0x16 ,0xe0 ,0x1c ,0xc5 ,0xd5 ,0x4a ,0x6e ,0xf9 ,0x6b ,0x41 ,0x56\n",
    "])\n",
    "anum=[i for i in range(256)]\n",
    "random.seed(124)\n",
    "rands=np.zeros([160,256],dtype=np.int32)\n",
    "rands2=np.zeros([160,256],dtype=np.int32)\n",
    "for i in range(160):\n",
    "    rands[i][0:256]=random.sample(anum,256)[0:256]\n",
    "for i in range(160):\n",
    "    rands2[i][0:256]=random.sample(anum,256)[0:256]\n",
    "    #print(rands[i]) \n",
    "#rand1.sort() 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71bfdebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#参数\n",
    "lr=0.01    #学习率\n",
    "gamma=0   #动量法\n",
    "epochs=1000    #代数\n",
    "bs=8*256      #小批量数\n",
    "\n",
    "#输入数据集  (net.no,mingw)\n",
    "num=160\n",
    "a=256*num\n",
    "x=torch.zeros([a,1,16*48],dtype=torch.float32)\n",
    "#赋予网络号标签\n",
    "for i in range(a):\n",
    "    x[i,0,256+int(i/256)]=1    \n",
    "#赋明文\n",
    "for i in range(a):\n",
    "    x[i,0,512+i%256]=1\n",
    "#print(x[a-3])  #1\n",
    "x=x.reshape([a,1,16,48])\n",
    "\n",
    "\n",
    "#目标数据 （miwen)\n",
    "#赋初值\n",
    "y=torch.zeros([a],dtype=torch.int64)\n",
    "for i in range(num):\n",
    "    for j in range(256):\n",
    "        y[i*256+j]=j\n",
    "#print(y[0:512]) #1\n",
    "#exor\n",
    "for i in range(a):\n",
    "    y[i]=y[i]^(key1[int(i/256)])\n",
    "#print(y[256*14:256*15]^key1[14]) #1\n",
    "#byte\n",
    "for i in range(a):\n",
    "    y[i]=byte[y[i]]\n",
    "#sbyte\n",
    "for i in range(a):\n",
    "    y[i]=rands[int(i/256)][y[i]]\n",
    "#print(y[a-1])\n",
    "#print(rands[15][byte[255^key1[15]]]) #1\n",
    "#sbyte2\n",
    "for i in range(a):\n",
    "    y[i]=rands2[int(i/256)][y[i]]\n",
    "\n",
    "    \n",
    "device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "#print(sys.getsizeof(x.storage()))\n",
    "#print(sys.getsizeof(y.storage()))\n",
    "dataset=TensorDataset(x,y)\n",
    "#print(dataset.data[0])\n",
    "data=DataLoader(dataset\n",
    "               ,batch_size=bs\n",
    "               ,drop_last=False)\n",
    "#for i in data:\n",
    "#    print(i[0].shape)\n",
    "finsig=torch.zeros([a,256],dtype=torch.float32)\n",
    "finsig=finsig.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "202bcda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#网络构建\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1=nn.Conv2d(1,16,3,padding=2)    #卷积\n",
    "        self.pool1=nn.MaxPool2d(2)  #最大池化\n",
    "        self.conv2=nn.Conv2d(16,32,3,padding=2)   #卷积\n",
    "        self.pool2=nn.MaxPool2d(2)            #最大池化\n",
    "        #self.conv3=nn.Conv2d(32,48,3)   #卷积\n",
    "        #self.pool3=nn.MaxPool2d(2)            #最大池化\n",
    "        \n",
    "        self.linear1=nn.Linear(5*13*32,2024,bias=True)  #两层全连接\n",
    "        self.linear2=nn.Linear(2024,256,bias=False)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=torch.tanh(self.conv1(x))   #前向传播 包括激活函数\n",
    "        x=self.pool1(x)\n",
    "        x=torch.tanh(self.conv2(x))\n",
    "        x=self.pool2(x)\n",
    "        #x=torch.tanh(self.conv3(x))\n",
    "        #x=self.pool3(x)\n",
    "        \n",
    "        x=x.view(-1,5*13*32)\n",
    "        x=torch.tanh(self.linear1(x))\n",
    "        output=F.softmax(self.linear2(x),dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0753c283",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义损失函数以及优化算法及迭代\n",
    "def train(net,lr):\n",
    "    start = time.time()\n",
    "    #MSE函数\n",
    "    #criterion=nn.MSELoss()\n",
    "    criterion=nn.NLLLoss() #定义多分类损失函数\n",
    "    telr=lr\n",
    "    #opt=optim.SGD(net.parameters(),lr=telr,momentum=gamma) #小批量优化算法\n",
    "    opt=optim.Adam(net.parameters(),lr=telr,betas=(0.15,0.15),eps=1e-08,amsgrad=True)\n",
    "    for epoch in range(epochs):\n",
    "        num1=0\n",
    "        for m,n in data:\n",
    "            x1=m.to(device,non_blocking=True)\n",
    "            y1=n.to(device,non_blocking=True)\n",
    "            sigma=net.forward(x1)       #前向传播\n",
    "            sigma1=torch.log(sigma)    #softmax+log+NLLLOSS=多分类交叉熵函数\n",
    "            loss=criterion(sigma1,y1)   #计算损失函数值\n",
    "            loss.backward()            #反向传播\n",
    "            opt.step()                 #权重更新\n",
    "            opt.zero_grad()            #梯度清零\n",
    "            #telr=lr-lr*(1-(torch.pow(torch.tanh(torch.tensor(-10+10*(epoch/epochs))),2)))+0.1  #学习率衰减函数\n",
    "           \n",
    "            if epoch%50==0 and num1==0:\n",
    "                print('epoch:{} 该epochs中首个loss值:{} '.format(epoch,loss))\n",
    "            \n",
    "            if epoch==epochs-1:\n",
    "                    finsig[num1*bs:num1*bs+bs]=sigma[0:bs]\n",
    "            del sigma,sigma1,loss,x1,y1\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            num1=num1+1\n",
    "    #统计结果正确的标签数量\n",
    "    num=0\n",
    "    fina=torch.max(finsig,1)[1]  #每个长度为256的标签中的最大值所在的索引就是目标字节值，这是训练结果的值\n",
    "    #y1=torch.max(y,1)[1]        #目标值\n",
    "    for i in range(a):       \n",
    "        temp=fina[i]-y[i]\n",
    "        if temp==0:\n",
    "            num=num+1\n",
    "    print('映射成功的个数:%d'%num)\n",
    "    end = time.time()\n",
    "    print('程序执行时间: ',end - start)\n",
    "    return finsig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3eb4c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型实例化和确定随机数种子\n",
    "torch.manual_seed(126)\n",
    "#torch.cuda.manual_seed(126)\n",
    "torch.cuda.manual_seed_all(126)\n",
    "torch.backends.cudnn.deterministic=True\n",
    "net=Model()\n",
    "net=net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "989baec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 该epochs中首个loss值:5.545890808105469 \n",
      "epoch:50 该epochs中首个loss值:5.525629043579102 \n",
      "epoch:100 该epochs中首个loss值:5.39963960647583 \n",
      "epoch:150 该epochs中首个loss值:4.993614673614502 \n",
      "epoch:200 该epochs中首个loss值:3.3082480430603027 \n",
      "epoch:250 该epochs中首个loss值:1.4958150386810303 \n",
      "epoch:300 该epochs中首个loss值:0.5645875930786133 \n",
      "epoch:350 该epochs中首个loss值:0.26352155208587646 \n",
      "epoch:400 该epochs中首个loss值:0.11797734349966049 \n",
      "epoch:450 该epochs中首个loss值:0.07722701877355576 \n",
      "epoch:500 该epochs中首个loss值:0.05599328875541687 \n",
      "epoch:550 该epochs中首个loss值:0.04341103136539459 \n",
      "epoch:600 该epochs中首个loss值:0.03526949882507324 \n",
      "epoch:650 该epochs中首个loss值:0.029592197388410568 \n",
      "epoch:700 该epochs中首个loss值:0.0254207793623209 \n",
      "epoch:750 该epochs中首个loss值:0.02223609946668148 \n",
      "epoch:800 该epochs中首个loss值:0.01973135583102703 \n",
      "epoch:850 该epochs中首个loss值:0.01771780289709568 \n",
      "epoch:900 该epochs中首个loss值:0.016063768416643143 \n",
      "epoch:950 该epochs中首个loss值:0.014683219604194164 \n",
      "映射成功的个数:40960\n",
      "程序执行时间:  1195.8256509304047\n"
     ]
    }
   ],
   "source": [
    "#训练与评估\n",
    "sigma=train(net,lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "458df92f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.min(\n",
       "values=tensor(0.7490, grad_fn=<MinBackward0>),\n",
       "indices=tensor(18174))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#求出上述网络中误差最大的标签的值\n",
    "temp=[0 for i in range(a)]\n",
    "temp=torch.tensor(temp,dtype=torch.float32)\n",
    "for i in range(a):\n",
    "    temp[i]=torch.max(sigma[i],dim=0)[0]\n",
    "torch.min(temp,dim=0)  #value就是误差最大的值，ind就是对应值的索引号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6af9cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存模型\n",
    "torch.save(net,'net1v2.1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a1256b",
   "metadata": {},
   "outputs": [],
   "source": [
    "size1=torch.zeros([2,256,256,768],dtype=torch.float32)\n",
    "print(sys.getsizeof(size1.storage())) #67108920 64M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fa2376",
   "metadata": {},
   "outputs": [],
   "source": [
    "402653240/(1024*1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afc5697",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
